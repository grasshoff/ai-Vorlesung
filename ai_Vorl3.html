<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gerd Graßhoff">
<meta name="dcterms.date" content="2024-05-02">

<title>Philosophie der AI – 3&nbsp; Charakter von LLMs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ai_Vorl4.html" rel="next">
<link href="./ai_Vorl2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ai_Vorl3.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Charakter von LLMs</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Charakter von LLMs</span></h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Gerd Graßhoff </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 2, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Philosophie der AI</a> 
        <div class="sidebar-tools-main">
    <a href="./Philosophie-der-AI.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><em>Philosophie der AI</em></span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_Vorl1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Was ist AI?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_Vorl2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Die Revolution der AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_Vorl3.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Charakter von LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_Vorl4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">LLM für Sprache</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_Vorl5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Sprache und Text</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_Vorl6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Denken mit Logik</span></span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LettreAI Studio</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Inhalt</h2>
   
  <ul>
  <li><a href="#vorlesung-philosophie-der-ai-generative-modelle-large-language-models-und-character-konfiguration" id="toc-vorlesung-philosophie-der-ai-generative-modelle-large-language-models-und-character-konfiguration" class="nav-link active" data-scroll-target="#vorlesung-philosophie-der-ai-generative-modelle-large-language-models-und-character-konfiguration"><span class="header-section-number">3.1</span> Vorlesung Philosophie der AI: Generative Modelle, Large Language Models und Character-Konfiguration</a></li>
  <li><a href="#die-revolution-der-generativen-ai-modelle" id="toc-die-revolution-der-generativen-ai-modelle" class="nav-link" data-scroll-target="#die-revolution-der-generativen-ai-modelle"><span class="header-section-number">3.2</span> Die Revolution der generativen AI-Modelle</a>
  <ul class="collapse">
  <li><a href="#large-language-models-als-kern-der-generativen-ai" id="toc-large-language-models-als-kern-der-generativen-ai" class="nav-link" data-scroll-target="#large-language-models-als-kern-der-generativen-ai"><span class="header-section-number">3.2.1</span> Large Language Models als Kern der generativen AI</a></li>
  <li><a href="#die-explosion-der-verfügbaren-modelle" id="toc-die-explosion-der-verfügbaren-modelle" class="nav-link" data-scroll-target="#die-explosion-der-verfügbaren-modelle"><span class="header-section-number">3.2.2</span> Die Explosion der verfügbaren Modelle</a></li>
  </ul></li>
  <li><a href="#die-funktionsweise-der-generativen-ai-modelle" id="toc-die-funktionsweise-der-generativen-ai-modelle" class="nav-link" data-scroll-target="#die-funktionsweise-der-generativen-ai-modelle"><span class="header-section-number">3.3</span> Die Funktionsweise der generativen AI-Modelle</a>
  <ul class="collapse">
  <li><a href="#semantische-ähnlichkeit-und-transformation" id="toc-semantische-ähnlichkeit-und-transformation" class="nav-link" data-scroll-target="#semantische-ähnlichkeit-und-transformation"><span class="header-section-number">3.3.1</span> Semantische Ähnlichkeit und Transformation</a></li>
  <li><a href="#character---die-formung-des-künstlichen-charakters" id="toc-character---die-formung-des-künstlichen-charakters" class="nav-link" data-scroll-target="#character---die-formung-des-künstlichen-charakters"><span class="header-section-number">3.3.2</span> Character - Die Formung des künstlichen Charakters</a></li>
  <li><a href="#metaregeln-und-kausales-schließen" id="toc-metaregeln-und-kausales-schließen" class="nav-link" data-scroll-target="#metaregeln-und-kausales-schließen"><span class="header-section-number">3.3.3</span> Metaregeln und kausales Schließen</a></li>
  <li><a href="#historisches-schließen" id="toc-historisches-schließen" class="nav-link" data-scroll-target="#historisches-schließen"><span class="header-section-number">3.3.4</span> Historisches Schließen</a></li>
  <li><a href="#die-bedeutung-des-kontexts" id="toc-die-bedeutung-des-kontexts" class="nav-link" data-scroll-target="#die-bedeutung-des-kontexts"><span class="header-section-number">3.3.5</span> Die Bedeutung des Kontexts</a></li>
  <li><a href="#agi---ein-umstrittenes-konzept" id="toc-agi---ein-umstrittenes-konzept" class="nav-link" data-scroll-target="#agi---ein-umstrittenes-konzept"><span class="header-section-number">3.3.6</span> AGI - Ein umstrittenes Konzept</a></li>
  <li><a href="#hermeneutik-als-herausforderung-für-ai" id="toc-hermeneutik-als-herausforderung-für-ai" class="nav-link" data-scroll-target="#hermeneutik-als-herausforderung-für-ai"><span class="header-section-number">3.3.7</span> Hermeneutik als Herausforderung für AI</a></li>
  <li><a href="#kontextvergrößerung-als-schlüssel-zum-verständnis" id="toc-kontextvergrößerung-als-schlüssel-zum-verständnis" class="nav-link" data-scroll-target="#kontextvergrößerung-als-schlüssel-zum-verständnis"><span class="header-section-number">3.3.8</span> Kontextvergrößerung als Schlüssel zum Verständnis</a></li>
  <li><a href="#ausblick" id="toc-ausblick" class="nav-link" data-scroll-target="#ausblick"><span class="header-section-number">3.3.9</span> Ausblick</a></li>
  <li><a href="#von-der-query-zur-instruktion" id="toc-von-der-query-zur-instruktion" class="nav-link" data-scroll-target="#von-der-query-zur-instruktion"><span class="header-section-number">3.3.10</span> Von der Query zur Instruktion</a></li>
  </ul></li>
  <li><a href="#die-schlüsselelemente-der-revolution-semantische-ähnlichkeit-und-regelhafte-textgenerierung" id="toc-die-schlüsselelemente-der-revolution-semantische-ähnlichkeit-und-regelhafte-textgenerierung" class="nav-link" data-scroll-target="#die-schlüsselelemente-der-revolution-semantische-ähnlichkeit-und-regelhafte-textgenerierung"><span class="header-section-number">3.4</span> Die Schlüsselelemente der Revolution: Semantische Ähnlichkeit und regelhafte Textgenerierung</a>
  <ul class="collapse">
  <li><a href="#wer-war-johann-wolfgang-goethe---eine-typische-google-frage" id="toc-wer-war-johann-wolfgang-goethe---eine-typische-google-frage" class="nav-link" data-scroll-target="#wer-war-johann-wolfgang-goethe---eine-typische-google-frage"><span class="header-section-number">3.4.1</span> Wer war Johann Wolfgang Goethe? - Eine typische Google-Frage</a></li>
  <li><a href="#die-grenzen-der-aktualität" id="toc-die-grenzen-der-aktualität" class="nav-link" data-scroll-target="#die-grenzen-der-aktualität"><span class="header-section-number">3.4.2</span> Die Grenzen der Aktualität</a></li>
  <li><a href="#interne-präferenzordnungen-und-regeln" id="toc-interne-präferenzordnungen-und-regeln" class="nav-link" data-scroll-target="#interne-präferenzordnungen-und-regeln"><span class="header-section-number">3.4.3</span> Interne Präferenzordnungen und Regeln</a></li>
  </ul></li>
  <li><a href="#die-qualität-der-internetressourcen-reicht-nicht-aus" id="toc-die-qualität-der-internetressourcen-reicht-nicht-aus" class="nav-link" data-scroll-target="#die-qualität-der-internetressourcen-reicht-nicht-aus"><span class="header-section-number">3.5</span> Die Qualität der Internetressourcen reicht nicht aus</a>
  <ul class="collapse">
  <li><a href="#die-notwendigkeit-seriöser-quellen" id="toc-die-notwendigkeit-seriöser-quellen" class="nav-link" data-scroll-target="#die-notwendigkeit-seriöser-quellen"><span class="header-section-number">3.5.1</span> Die Notwendigkeit seriöser Quellen</a></li>
  </ul></li>
  <li><a href="#die-herausforderung-wahrheit-und-wissen" id="toc-die-herausforderung-wahrheit-und-wissen" class="nav-link" data-scroll-target="#die-herausforderung-wahrheit-und-wissen"><span class="header-section-number">3.6</span> Die Herausforderung: Wahrheit und Wissen</a>
  <ul class="collapse">
  <li><a href="#der-wissenschaftliche-prozess" id="toc-der-wissenschaftliche-prozess" class="nav-link" data-scroll-target="#der-wissenschaftliche-prozess"><span class="header-section-number">3.6.1</span> Der wissenschaftliche Prozess</a></li>
  <li><a href="#die-offene-frage-der-umgang-mit-alternativen-lösungen" id="toc-die-offene-frage-der-umgang-mit-alternativen-lösungen" class="nav-link" data-scroll-target="#die-offene-frage-der-umgang-mit-alternativen-lösungen"><span class="header-section-number">3.6.2</span> Die offene Frage: Der Umgang mit alternativen Lösungen</a></li>
  </ul></li>
  <li><a href="#beispiele-zur-veranschaulichung" id="toc-beispiele-zur-veranschaulichung" class="nav-link" data-scroll-target="#beispiele-zur-veranschaulichung"><span class="header-section-number">3.7</span> Beispiele zur Veranschaulichung</a>
  <ul class="collapse">
  <li><a href="#die-macht-des-chats" id="toc-die-macht-des-chats" class="nav-link" data-scroll-target="#die-macht-des-chats"><span class="header-section-number">3.7.1</span> Die Macht des Chats</a></li>
  <li><a href="#kollaborative-intelligenz" id="toc-kollaborative-intelligenz" class="nav-link" data-scroll-target="#kollaborative-intelligenz"><span class="header-section-number">3.7.2</span> Kollaborative Intelligenz</a></li>
  </ul></li>
  <li><a href="#herausforderungen-und-grenzen-aktueller-ki-modelle" id="toc-herausforderungen-und-grenzen-aktueller-ki-modelle" class="nav-link" data-scroll-target="#herausforderungen-und-grenzen-aktueller-ki-modelle"><span class="header-section-number">3.8</span> Herausforderungen und Grenzen aktueller KI-Modelle</a>
  <ul class="collapse">
  <li><a href="#einstellbare-konversationsstile" id="toc-einstellbare-konversationsstile" class="nav-link" data-scroll-target="#einstellbare-konversationsstile"><span class="header-section-number">3.8.1</span> Einstellbare Konversationsstile</a></li>
  <li><a href="#fragen-jenseits-von-wikipedia" id="toc-fragen-jenseits-von-wikipedia" class="nav-link" data-scroll-target="#fragen-jenseits-von-wikipedia"><span class="header-section-number">3.8.2</span> Fragen jenseits von Wikipedia</a></li>
  <li><a href="#zukünftige-herausforderungen" id="toc-zukünftige-herausforderungen" class="nav-link" data-scroll-target="#zukünftige-herausforderungen"><span class="header-section-number">3.8.3</span> Zukünftige Herausforderungen</a></li>
  </ul></li>
  <li><a href="#aktuelle-grenzen-und-zukünftige-möglichkeiten" id="toc-aktuelle-grenzen-und-zukünftige-möglichkeiten" class="nav-link" data-scroll-target="#aktuelle-grenzen-und-zukünftige-möglichkeiten"><span class="header-section-number">3.9</span> Aktuelle Grenzen und zukünftige Möglichkeiten</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="vorlesung-philosophie-der-ai-generative-modelle-large-language-models-und-character-konfiguration" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="vorlesung-philosophie-der-ai-generative-modelle-large-language-models-und-character-konfiguration"><span class="header-section-number">3.1</span> Vorlesung Philosophie der AI: Generative Modelle, Large Language Models und Character-Konfiguration</h2>
<p>Willkommen zurück zur dritten Vorlesung der Philosophie der AI! Bevor wir tiefer in die faszinierende Welt der generativen Modelle eintauchen, lassen Sie mich einige organisatorische Aspekte ansprechen. Ich möchte Ihnen versichern, dass trotz der verwirrenden Ablehnungsbescheide des Agnes-Zulassungssystems jeder immatrikulierte Student, auch ÜWP, zu dieser Vorlesung zugelassen ist, solange wir Platz in diesem Saal haben. Die Philosophische Fakultät und ich persönlich garantieren Ihnen dies. Es ist lediglich wichtig sicherzustellen, dass Ihre Studienleistungen korrekt in das Prüfungssystem Ihres Hauptfaches eingetragen werden. Bei Fragen oder Bedenken wenden Sie sich bitte an das zuständige Prüfungsbüro oder an Frau Krause vom Sekretariat der Philosophie. Wir werden gemeinsam sicherstellen, dass Ihre Leistungen entsprechend dokumentiert werden.</p>
<p>Später in der Vorlesung werde ich Ihnen außerdem mögliche Projektarbeiten vorstellen, die Sie im Rahmen eines Gesamtforschungsvorhabens in Zusammenarbeit mit wissenschaftlichen Akademien und der Stiftung Deutscher Klassik in Weimar absolvieren können. Je nach Ergebnissen dieser Übungen überlegen wir, die Resultate am Ende des Semesters öffentlichkeitswirksam zu präsentieren. Ich freue mich darauf, Ihnen die Details in Kürze unterbreiten zu können.</p>
</section>
<section id="die-revolution-der-generativen-ai-modelle" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="die-revolution-der-generativen-ai-modelle"><span class="header-section-number">3.2</span> Die Revolution der generativen AI-Modelle</h2>
<p>In den letzten beiden Stunden haben wir uns bereits intensiv mit den verschiedenen Modellen der AI oder KI auseinandergesetzt. Ein Begriff, der sich zunehmend etabliert, ist der der generativen AI-Modelle. Diese Modelle zeichnen sich dadurch aus, dass sie in der Lage sind, abhängig von einem gegebenen Input, Texte, Bilder, Videos oder Audiodaten zu erzeugen - sie generieren etwas Neues.</p>
<section id="large-language-models-als-kern-der-generativen-ai" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="large-language-models-als-kern-der-generativen-ai"><span class="header-section-number">3.2.1</span> Large Language Models als Kern der generativen AI</h3>
<p>Im Kern dieser generativen AI stehen die sogenannten Large Language Models (LLM). Wie der Name schon sagt, handelt es sich hierbei um umfangreiche Sprachmodelle, die auch dann zentral bleiben, wenn es um die Verarbeitung und Interpretation von Bildern geht. Die Ebene des Sprachverstehens und -verarbeitens ist fundamental für alle Modelle der künstlichen Intelligenz, mit denen wir es hier zu tun haben.</p>
</section>
<section id="die-explosion-der-verfügbaren-modelle" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="die-explosion-der-verfügbaren-modelle"><span class="header-section-number">3.2.2</span> Die Explosion der verfügbaren Modelle</h3>
<p>Derzeit gibt es etwa 100 verschiedene Vorschläge für solche Modelle, von denen einige nur über Lizenzen und Zugriffsbarrieren nutzbar sind, während die Mehrzahl bereits Open Access zur Verfügung steht. Die Anzahl der angebotenen Modelle explodiert förmlich, wobei jedes Modell seine eigenen spezifischen Kompetenzen und Fähigkeiten aufweist.</p>
</section>
</section>
<section id="die-funktionsweise-der-generativen-ai-modelle" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="die-funktionsweise-der-generativen-ai-modelle"><span class="header-section-number">3.3</span> Die Funktionsweise der generativen AI-Modelle</h2>
<section id="semantische-ähnlichkeit-und-transformation" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="semantische-ähnlichkeit-und-transformation"><span class="header-section-number">3.3.1</span> Semantische Ähnlichkeit und Transformation</h3>
<p>Die derzeitige Generation der Modelle arbeitet im Wesentlichen mit zwei revolutionären Komponenten:</p>
<ol type="1">
<li><p>Semantische Ähnlichkeit: Die Modelle sind in der Lage, Bedeutungsgleichheiten oder -ähnlichkeiten zu identifizieren, anstatt nur nach exakten Stichwörtern zu suchen.</p></li>
<li><p>Transformation: Basierend auf diesen semantischen Ähnlichkeiten können die Modelle bei einem gegebenen Input einen passenden Output generieren.</p></li>
</ol>
<p>Die Kombination dieser beiden Aspekte ist extrem weitreichend, da sie eine Verallgemeinerung der Bedeutung von Textinhalten und eine Transformation dieser Regeln ermöglicht. Ähnlich wie wir Menschen allgemeine Regeln aufstellen können, sind diese Modelle in der Lage, verallgemeinerte Regeln zu erkennen und anzuwenden.</p>
</section>
<section id="character---die-formung-des-künstlichen-charakters" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="character---die-formung-des-künstlichen-charakters"><span class="header-section-number">3.3.2</span> Character - Die Formung des künstlichen Charakters</h3>
<p>Zusätzlich zu den Sprachkompetenzen kommt nun ein dritter Aspekt ins Spiel, der die Philosophie auf den Plan ruft: der sogenannte “Character”. Die generativen AI-Modelle verhalten sich in der Kommunikation fast so, als würde man mit einer menschlichen Person interagieren. Durch die Beherrschung der semantischen Verallgemeinerung und der Regeltransformation können wir die Art und Weise, wie diese Modelle Regeln erstellen, modifizieren und sie so charakterlich formen.</p>
<section id="stilistische-aspekte-des-characters" class="level4" data-number="3.3.2.1">
<h4 data-number="3.3.2.1" class="anchored" data-anchor-id="stilistische-aspekte-des-characters"><span class="header-section-number">3.3.2.1</span> Stilistische Aspekte des Characters</h4>
<p>Diese Charakterformung kann sehr weit reichen und umfasst zunächst oberflächliche, stilistische Aspekte wie:</p>
<ul>
<li>Sprache der Antworten</li>
<li>Schreibstil (z.B. im Stil von Ernest Hemingway)</li>
<li>Datenausgabe (knapper, schematisiert, in bestimmten Formaten)</li>
<li>Literarische Stile (z.B. griechische Hexameter, Stil eines Homer)</li>
</ul>
</section>
<section id="philosophische-aspekte-des-characters" class="level4" data-number="3.3.2.2">
<h4 data-number="3.3.2.2" class="anchored" data-anchor-id="philosophische-aspekte-des-characters"><span class="header-section-number">3.3.2.2</span> Philosophische Aspekte des Characters</h4>
<p>Noch interessanter wird es bei den philosophischen Aspekten des Characters, also den formalen inhaltlichen Regeln des Nachdenkens, Resonierens und Formulierens von Arbeitsverfahren und Denkprozessen. Hier geht es darum, welche Regeln diese Modelle befolgen sollen, um die gegebenen Instruktionen zu erfüllen. Dieser Aspekt ist in der derzeitigen Entwicklung noch unterbelichtet, obwohl alle Entwickler wissen, dass er berücksichtigt werden muss.</p>
</section>
</section>
<section id="metaregeln-und-kausales-schließen" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="metaregeln-und-kausales-schließen"><span class="header-section-number">3.3.3</span> Metaregeln und kausales Schließen</h3>
<p>Ein wichtiger Teilbereich der Charakterformung sind die Metaregeln, insbesondere im Bereich des kausalen Schließens. Für viele wissenschaftliche und nicht-wissenschaftliche Bereiche, wie etwa die Medizin, ist dies von großer Bedeutung. Fragen der Diagnostik, der Vorstellungen über Krankheiten und Krankheitsverläufe erfordern kausales Schließen. Bisher sind diese Regeln in den Modellen nicht systematisch vorhanden, sondern werden lediglich durch das Training anhand von Publikationen antrainiert. Die Ableitung allgemeiner Metaregeln zum korrekten Schließen und zu wissenschaftlichen Verfahren ist eine der großen Herausforderungen für die Zukunft.</p>
</section>
<section id="historisches-schließen" class="level3" data-number="3.3.4">
<h3 data-number="3.3.4" class="anchored" data-anchor-id="historisches-schließen"><span class="header-section-number">3.3.4</span> Historisches Schließen</h3>
<p>Ein weiterer interessanter Bereich, gerade für die historischen Wissenschaften, ist das historische Schließen. Wenn es darum geht, historische Aussagen über Biografien bekannter Persönlichkeiten zu treffen, wer was erlebt und geprägt hat, sind spezifische Regeln gefragt. Auch diese Regeln müssen den Programmen erst noch beigebracht werden. Bisher haben sie nur anhand von Beispielen gelernt, einen kleinen Bereich anzuwenden, der jedoch in seinen Qualitäten limitiert ist und formale Trainingszusatzfunktionen erfordert. Ich bin zuversichtlich, dass diese Probleme innerhalb der nächsten zwei Jahre gelöst sein werden.</p>
</section>
<section id="die-bedeutung-des-kontexts" class="level3" data-number="3.3.5">
<h3 data-number="3.3.5" class="anchored" data-anchor-id="die-bedeutung-des-kontexts"><span class="header-section-number">3.3.5</span> Die Bedeutung des Kontexts</h3>
<p>Neben den Regeln spielt auch der sogenannte Kontext eine entscheidende Rolle für den Input der Transformation von generativen Modellen. Der Kontext umfasst alle sprachlich ausgedrückten Zusatzinformationen, die das Programm benötigt, um zusätzlich zu einer bestimmten Instruktion einen entsprechenden Output zu generieren. Je größer und präziser dieser Kontext ist, desto besser kann die eigentliche Aufgabe inhaltlich korrekt verstanden und gelöst werden.</p>
<section id="technische-herausforderungen-des-kontexts" class="level4" data-number="3.3.5.1">
<h4 data-number="3.3.5.1" class="anchored" data-anchor-id="technische-herausforderungen-des-kontexts"><span class="header-section-number">3.3.5.1</span> Technische Herausforderungen des Kontexts</h4>
<p>Eine der interessantesten technischen Herausforderungen ist es, die Größe des Kontexts maximal zu gestalten, ohne dabei die Größe des Modells exponentiell wachsen zu lassen. Denn mit einem zu großen Modell steigen auch die Anforderungen an Hardware, Software und Stromverbrauch, was die praktische Anwendbarkeit einschränkt. Es gilt also, die richtige Balance zwischen Kontextgröße und Modellgröße zu finden, um optimale Ergebnisse zu erzielen, ohne die Bearbeitungsdauer und die Ressourcen übermäßig zu beanspruchen.## Kontextvergrößerung und Sachkompetenz bei AI-Modellen</p>
<p>In den letzten Monaten hat sich in der Welt der künstlichen Intelligenz viel getan. Täglich verfolge ich die Entwicklungen und bin fasziniert von den Fortschritten, aber auch besorgt über die Herausforderungen, die sich dabei auftun. Ein Stichwort, das mir besonders im Gedächtnis geblieben ist, lautet “RAG” - zusätzliche Ressourcen als Extra-Input für den Kontext. Die Idee dahinter ist, den AI-Modellen mehr Informationen zur Verfügung zu stellen, um ihre Sachkompetenz zu erweitern. Doch obwohl in den letzten fünf Monaten intensiv daran geforscht wurde, bleiben die Ergebnisse meiner Meinung nach oberflächlich und unzureichend.</p>
<p>Die Sachkompetenz ist eine der interessantesten zusätzlichen Anforderungen an AI-Modelle, doch aus prinzipiellen Gründen verfügen sie derzeit nicht darüber. Stattdessen kaschieren sie dieses Defizit oft geschickt. Als Warnung an alle, die Informationen von AI-Modellen nutzen: Auch wenn die Antworten überzeugend und plausibel klingen, unterliegen sie keinerlei Sachprüfung. Die Wahrscheinlichkeit, dass sie falsch sind, ist sehr hoch.</p>
</section>
</section>
<section id="agi---ein-umstrittenes-konzept" class="level3" data-number="3.3.6">
<h3 data-number="3.3.6" class="anchored" data-anchor-id="agi---ein-umstrittenes-konzept"><span class="header-section-number">3.3.6</span> AGI - Ein umstrittenes Konzept</h3>
<p>Immer wieder tauchen in der Debatte um künstliche Intelligenz modische Schlagworte auf, die ebenso schnell wieder verschwinden. Ein Beispiel dafür ist die “Artificial General Intelligence” (AGI). Erst letztes Jahr erschien in der New York Times eine Stellungnahme von Kollegen, die argumentierten, warum AI prinzipiell nicht intelligent sein kann. Ihr Hauptargument: Es handle sich lediglich um probabilistische Rechnungen, die auf Wahrscheinlichkeiten basieren. Doch dieses Argument lässt sich auch auf das menschliche Gehirn übertragen - letztlich sind auch dort elektrische Impulse zwischen Neuronen für unsere kognitiven Leistungen verantwortlich. Selbst wenn diese Impulse deterministisch wären, wäre das kein Gegenargument dagegen, dass die daraus resultierenden Leistungen dem entsprechen, was wir als intelligentes Handeln und Denken bezeichnen.</p>
<p>Die optimistische Gegenreaktion auf solche Kritik lautet oft, dass die Entwicklung schneller voranschreiten wird als erwartet - so wie beim Schachspiel, wo Computer mittlerweile menschliche Großmeister übertreffen. Manche prophezeien, dass es bald Modelle geben wird, die das gesamte Spektrum der menschlichen kognitiven Leistungsfähigkeit überholen werden. Doch angesichts der enormen Dynamik in diesem Bereich halte ich es für unseriös, weitreichende Prognosen über die nächsten Monate hinaus abzugeben.</p>
<p>Ob es jemals eine Computerleistung geben wird, die alle kognitiven Leistungsbereiche des Menschen übersteigt, halte ich für eine müßige Frage. Diese Debatte gab es schon vor 30 Jahren, als klar war, dass Maschinen beim Textverständnis nicht annähernd mit Menschen mithalten konnten. Gleichzeitig konnten Computer aber bereits meisterhaft numerische Mathematik betreiben und beispielsweise Differenzialgleichungen lösen - eine Leistung, zu der kein Mensch in der Lage wäre. In vielen Bereichen der technisch-mathematischen Informatik bringen maschinelle Verfahren heute ein so hohes Problemlösungsvermögen mit, dass kein individueller Mensch mehr dagegen antreten kann. Einzelne Sektoren werden also zweifellos durch maschinelle Verfahren wesentlich kompetenter und sicherer gelöst als durch menschliche Akteure.</p>
</section>
<section id="hermeneutik-als-herausforderung-für-ai" class="level3" data-number="3.3.7">
<h3 data-number="3.3.7" class="anchored" data-anchor-id="hermeneutik-als-herausforderung-für-ai"><span class="header-section-number">3.3.7</span> Hermeneutik als Herausforderung für AI</h3>
<p>Ein Bereich, der für die Geisteswissenschaften von besonderer Bedeutung ist, ist die Interpretation von Texten. Dabei geht es darum, den Inhalt kritisch zu hinterfragen und zu verstehen - eine Leistung, die bisher dem Menschen vorbehalten war. Ziel ist es, zu einem Textverständnis zu gelangen, das nicht nur auf der Lektüre von Trainingsdatenbeständen beruht, sondern auf echten Interpretationsleistungen. Dazu müssen hermeneutische Verfahren, wie sie jeder Geisteswissenschaftler bei der Lektüre seiner Quellen anwendet, auch im Computer-Kontext umgesetzt werden. Ich habe keinen Zweifel daran, dass dies eines Tages möglich sein wird.</p>
<p>Doch was nützt es, solche Leistungen zur AGI hinzuzuzählen oder nicht? Manche Modelle können etwas, andere nicht - das stellen wir gerade in der Entwicklung der generativen AI-Modelle fest. Aufgrund ihrer Trainingsgeschichte haben viele Modelle beispielsweise ein ansehnliches Verständnis von Latein, obwohl der praktische Nutzen dafür gering ist. Doch diese Kompetenzen könnten schon bald wieder verschwinden, wenn die Modelle optimiert werden, um auch auf Smartphones zu laufen. Diese Optimierung bedeutet eine Reduzierung der Kompetenzen auf das Nötigste - das Gegenteil einer Entwicklung hin zu einer allgemeinen Kompetenz. Stattdessen erwarte ich eine zunehmende Spezialisierung der Modelle auf bestimmte Aufgaben wie Rechnen, Sprachverständnis oder diagnostisches Denken.</p>
</section>
<section id="kontextvergrößerung-als-schlüssel-zum-verständnis" class="level3" data-number="3.3.8">
<h3 data-number="3.3.8" class="anchored" data-anchor-id="kontextvergrößerung-als-schlüssel-zum-verständnis"><span class="header-section-number">3.3.8</span> Kontextvergrößerung als Schlüssel zum Verständnis</h3>
<p>Wenn wir über den Kontext sprechen, meinen wir ganz schlicht die Anzahl der Token (Wörter und Satzzeichen), die ein Modell berücksichtigen kann, um den Sinn einer Anfrage zu verstehen. Vor einem halben Jahr lag diese Zahl bei etwa 1.000 - das entspricht ungefähr drei Seiten Text. Alles darüber hinaus wurde nicht berücksichtigt. Wenn man also Informationen aus längeren Texten wie Enzyklopädie-Einträgen benötigte, war es unmöglich, diese vollständig in den Kontext der Modelle einzubringen. Irgendwo wurde notwendigerweise abgeschnitten und Informationen gingen verloren.</p>
<p>In den letzten sechs Monaten wurde daher intensiv daran gearbeitet, den Kontext zu vergrößern. Die Standardmodelle, die ich für die Illustration in dieser Vorlesung nutze, stammen aus dem Bereich “Cloth” (geschrieben wie das englische Wort für Tuch) und haben mittlerweile einen Kontext von 200.000 Wörtern. Das ist schon eine beachtliche Menge, in der sich viele Informationen unterbringen lassen.</p>
<p>Doch auch hier gibt es Vortäuscher, die einen großen Kontext suggerieren, ihn aber faktisch nicht nutzen. Man muss immer kritisch hinterfragen, ob die angegebene Kontextgröße auch wirklich gleichermaßen bei der Suche nach einer Antwort berücksichtigt wird.</p>
<section id="der-heunadeltest" class="level4" data-number="3.3.8.1">
<h4 data-number="3.3.8.1" class="anchored" data-anchor-id="der-heunadeltest"><span class="header-section-number">3.3.8.1</span> Der Heunadeltest</h4>
<p>Ein praktischer Test dafür ist der sogenannte Heunadeltest. Die Idee ist folgende: In einem beliebigen Text, beispielsweise Goethes gesammelten Werken, fügt ein Nutzer an einer Stelle einen selbst gewählten Satz oder eine Formulierung ein. Das könnte etwas sein, das Goethe nie geschrieben hätte, wie “Trump ist blöd”. Die Aufgabe für das Modell besteht dann darin, genau diese Feststellung - nicht wortgleich, sondern inhaltlich - wiederzufinden. Es geht also darum, die Nadel im Heuhaufen zu finden.</p>
<p>Man weiß nur, dass Goethe irgendwo in seinen gesammelten Werken eine Äußerung zu Trump getätigt hat, kennt aber weder den genauen Wortlaut noch die Stelle. Vielleicht wird Trump nicht einmal namentlich erwähnt, sondern nur als “der Präsident, der 2018 im Amt war” umschrieben. Diese Nadel im Heuhaufen zu finden, ist eine anspruchsvolle Aufgabe. Es reicht nicht, einen großen Textbestand zu beherrschen - man muss nach etwas suchen, dessen Bedeutung man kennt, aber dessen genauen Wortlaut nicht.</p>
<p>An solchen Tests lässt sich gut erkennen, ob die verwendeten Modelle tatsächlich die Größe des Kontextes haben, die nötig ist, um einen gesamten Textbestand zu berücksichtigen. Es wäre nicht erlaubt, den Gesamttext in praktikable Teile zu unterteilen und nur in diesen zu suchen. Wenn, dann muss die Suche in Toto erfolgen. Und Goethes gesammelte Werke umfassen definitiv mehr als 200.000 Wörter. Das sprengt das Leistungsvermögen der meisten, wenn nicht aller mir bekannten Modelle.</p>
</section>
</section>
<section id="ausblick" class="level3" data-number="3.3.9">
<h3 data-number="3.3.9" class="anchored" data-anchor-id="ausblick"><span class="header-section-number">3.3.9</span> Ausblick</h3>
<p>Solche spezifischen Aufgaben sind meiner Meinung nach eine wesentlich bessere Beurteilung der Leistungsfähigkeit von AI-Modellen als generelle Kriterien wie AGI. Ein Katalog von Herausforderungen, die ein Modell meistern muss, um eine bestimmte Hürde zu überschreiten - das scheint mir der richtige Weg zu sein, um die Entwicklung voranzutreiben und zu bewerten.</p>
<p>In der nächsten Vorlesung werden wir uns genauer mit den sprachlichen Ausdrücken beschäftigen, die als Auslöser für bestimmte Reaktionen der Modelle dienen. Diese Instruktionen spielen eine entscheidende Rolle für das Verständnis und die Fähigkeiten der AI. Ich freue mich darauf, dieses faszinierende Thema mit Ihnen zu erkunden.## Die Bedeutung von Instruktionen für AI-Modelle</p>
<p>In der Welt der künstlichen Intelligenz spielen Instruktionen eine entscheidende Rolle. Sie sind das Herzstück der Interaktion zwischen Mensch und Maschine, denn sie geben den AI-Modellen die nötigen Anweisungen, um eine Aufgabe adäquat zu lösen. Doch nicht jede Aussage eignet sich als Instruktion. Eine simple Feststellung wie “Der Hund ist schwarz” suggeriert nichts, legt nichts nahe und fordert nicht dazu auf, etwas zu tun. Sie ist zu allgemein und vage, als dass man sie sachlich beurteilen könnte.</p>
<p>Die meisten AI-Modelle sind darauf trainiert, auf jede Anfrage eine Antwort zu generieren, selbst wenn die Instruktion unklar oder nicht-kommunikativ ist. Hier zeigen sich die Unterschiede zwischen den verschiedenen Modellen in der Art und Weise, wie sie mit solchen Situationen umgehen.</p>
</section>
<section id="von-der-query-zur-instruktion" class="level3" data-number="3.3.10">
<h3 data-number="3.3.10" class="anchored" data-anchor-id="von-der-query-zur-instruktion"><span class="header-section-number">3.3.10</span> Von der Query zur Instruktion</h3>
<p>Vor einem Jahr waren Queries, ähnlich wie Google-Anfragen, noch sehr populär. Doch heute haben Instruktionen diese abgelöst und einen allgemeineren Aufgabenbereich eröffnet. Instruktionen sind derzeit das wichtigste Phänomen bei der Übergabe von sprachlich artikulierten Aufträgen an AI-Modelle.</p>
<p>Im Kern geht es darum, dass die Modelle in der Lage sein müssen, Instruktionen zu verstehen und auszuführen. Philosophisch gesehen handelt es sich um Handlungsanweisungen, die auf verschiedenste Anwendungsbereiche abzielen und die Modelle dazu anleiten, entsprechende Lösungen zu generieren.</p>
</section>
</section>
<section id="die-schlüsselelemente-der-revolution-semantische-ähnlichkeit-und-regelhafte-textgenerierung" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="die-schlüsselelemente-der-revolution-semantische-ähnlichkeit-und-regelhafte-textgenerierung"><span class="header-section-number">3.4</span> Die Schlüsselelemente der Revolution: Semantische Ähnlichkeit und regelhafte Textgenerierung</h2>
<p>Die Revolution in der Ausführung von Instruktionen besteht im Wesentlichen aus zwei Komponenten: der semantischen Ähnlichkeit und der Kombination mit regelhafter Textgenerierung. Doch wie wichtig der Kontext dabei ist, möchte ich Ihnen anhand einiger Beispiele verdeutlichen.</p>
<section id="wer-war-johann-wolfgang-goethe---eine-typische-google-frage" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="wer-war-johann-wolfgang-goethe---eine-typische-google-frage"><span class="header-section-number">3.4.1</span> Wer war Johann Wolfgang Goethe? - Eine typische Google-Frage</h3>
<p>Beginnen wir mit einer Frage, die man normalerweise in eine Suchmaschine eingeben würde: “Wer war Johann Wolfgang Goethe?” Wenn wir diese Frage in das AI-Modell eingeben, erwarten wir eine Antwort, die sachlich detailliert und informativ ist. Und genau das liefert das Modell auch.</p>
<p>Aber woher stammen diese Informationen? Die Antwort ist einfach: aus den Trainingsdaten. Alle großen AI-Modelle wurden auf der gesamten Wikipedia, auf Millionen von wissenschaftlichen Publikationen und auf Übersetzungskorpora, einschließlich deutsch-englischer Werke, trainiert.</p>
<section id="die-herausforderung-der-epistemischen-qualität" class="level4" data-number="3.4.1.1">
<h4 data-number="3.4.1.1" class="anchored" data-anchor-id="die-herausforderung-der-epistemischen-qualität"><span class="header-section-number">3.4.1.1</span> Die Herausforderung der epistemischen Qualität</h4>
<p>Doch obwohl die Antwort des Modells auf den ersten Blick sehr fundiert wirkt, fehlt etwas Entscheidendes: die epistemische Qualität. Die Informationen wurden zwar verarbeitet, aber nicht systematisch auf ihre Korrektheit geprüft. Die Modelle haben keinerlei Mittel, Falschinformationen zu erkennen.</p>
<p>Das ist eine Herausforderung, an der wir intensiv arbeiten. Denn obwohl die Sprachkompetenz der Modelle beeindruckend ist, mangelt es noch an echter Sachkompetenz.</p>
</section>
</section>
<section id="die-grenzen-der-aktualität" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="die-grenzen-der-aktualität"><span class="header-section-number">3.4.2</span> Die Grenzen der Aktualität</h3>
<p>Ein weiteres Problem ist die Aktualität der Daten. Meistens hören die Daten, auf denen die Modelle trainiert wurden, ab einem gewissen Datum auf. Auch wenn sich die Entwickler bemühen, die Modelle zu aktualisieren, heißt das nicht, dass wirklich alle Informationen berücksichtigt und abgewogen wurden.</p>
<section id="widersprüchliche-informationen---eine-logische-herausforderung" class="level4" data-number="3.4.2.1">
<h4 data-number="3.4.2.1" class="anchored" data-anchor-id="widersprüchliche-informationen---eine-logische-herausforderung"><span class="header-section-number">3.4.2.1</span> Widersprüchliche Informationen - eine logische Herausforderung</h4>
<p>Viele Informationen sind widersprüchlich und damit muss man umgehen. Das ist philosophisch extrem interessant, denn aus einem Widerspruch kann man logisch gesehen alles schlussfolgern. Logisches Schließen allein löst dieses Problem nicht. Man muss präferieren.</p>
</section>
</section>
<section id="interne-präferenzordnungen-und-regeln" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="interne-präferenzordnungen-und-regeln"><span class="header-section-number">3.4.3</span> Interne Präferenzordnungen und Regeln</h3>
<p>Im Hintergrund arbeiten die Modelle mit langen Listen von Alternativen zu verschiedensten Bereichen. Es gibt Präferenzordnungen, die den Modellen beigebracht wurden, um mit alternativen Antworten umzugehen. Dazu gehören auch intern trainierte allgemeine Präferenzregeln.</p>
</section>
</section>
<section id="die-qualität-der-internetressourcen-reicht-nicht-aus" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="die-qualität-der-internetressourcen-reicht-nicht-aus"><span class="header-section-number">3.5</span> Die Qualität der Internetressourcen reicht nicht aus</h2>
<p>Kommen wir zurück zur Frage der Qualität von Informationen. Es gibt unterschiedliche Meinungen darüber, ob die Technologie allein ausreicht, um Informationen zu verifizieren. Ich bin da anderer Ansicht.</p>
<section id="die-notwendigkeit-seriöser-quellen" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="die-notwendigkeit-seriöser-quellen"><span class="header-section-number">3.5.1</span> Die Notwendigkeit seriöser Quellen</h3>
<p>Für viele entscheidende Fragen, gerade im historischen Bereich, braucht man faktisches Wissen in Details, das man sehr umfangreich suchen muss. Das Internet allein ist kein Qualitätsauszeichnungsmerkmal. Deswegen werden Internetquellen an Universitäten auch nicht als seriöse wissenschaftliche Quellen akzeptiert.</p>
<p>Man muss seine Nachweise nach den Regeln der Kunst sachlich korrekt und gerechtfertigt ausweisen. Ein simpler Internetverweis reicht da nicht. Das liegt nicht an Konkurrenzdenken, sondern an der oft mangelhaften Qualität der Informationen im Internet.</p>
</section>
</section>
<section id="die-herausforderung-wahrheit-und-wissen" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="die-herausforderung-wahrheit-und-wissen"><span class="header-section-number">3.6</span> Die Herausforderung: Wahrheit und Wissen</h2>
<p>Es geht letztlich darum, Informationen zu finden, die nach bestem Wissen und Gewissen sachlich korrekt und plausibel wahr sind. Dabei geht es nicht um unumstößliche Fehlerfreiheit, sondern um Wissen, das Wahrheit impliziert. Dieses Wissen zu erlangen, ist ein Wert an sich.</p>
<section id="der-wissenschaftliche-prozess" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="der-wissenschaftliche-prozess"><span class="header-section-number">3.6.1</span> Der wissenschaftliche Prozess</h3>
<p>Die historische Entwicklung der Wissenschaft hat über Jahrtausende Verfahren herausgearbeitet, wie man in einer großen Gruppe von Spezialisten ein kritisches Potenzial entwickelt, um maximal plausible, korrekte Antworten zu finden. Dieser Prozess ist reguliert und nicht trivial. Es geht nicht um simple Meinungsumfragen oder Mehrheitsentscheidungen.</p>
</section>
<section id="die-offene-frage-der-umgang-mit-alternativen-lösungen" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="die-offene-frage-der-umgang-mit-alternativen-lösungen"><span class="header-section-number">3.6.2</span> Die offene Frage: Der Umgang mit alternativen Lösungen</h3>
<p>Wie geht man aber nun mit einer Mehrzahl an gerechtfertigten alternativen Lösungsvorschlägen um? Das ist eine Frage, die ich für eine spätere Vorlesung offen lassen möchte. Kein aktuelles AI-Modell hat dafür im Ansatz eine Lösung.</p>
<p>Was wir bisher haben, ist im Grunde genommen nur das “Sprachgeplapper” aus den Informationen von Wikipedia und anderen Quellen. Aber die epistemische Frage, die möchte ich weiter verfolgen. Denn das ist die philosophische Herausforderung, der sich die AI und auch diese Vorlesung stellen muss.</p>
<p>Die AI muss Regeln und Verfahren entwickeln und befolgen, wie Maschinenmodelle mit der Frage nach Wahrheit und gerechtfertigtem Wissen umgehen können. Das ist die Aufgabe, vor der wir stehen.</p>
</section>
</section>
<section id="beispiele-zur-veranschaulichung" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="beispiele-zur-veranschaulichung"><span class="header-section-number">3.7</span> Beispiele zur Veranschaulichung</h2>
<p>Lassen Sie mich nun anhand einiger Interaktionen verschiedene Aspekte der Kompetenz, aber auch der Limitierung dieser Modelle zeigen.</p>
<ul>
<li>Beispiel 1: Eine typische Wikipedia-Antwort</li>
<li>Beispiel 2: Die Limitierung des Sprachverstehens</li>
<li>Beispiel 3: Die Herausforderung des Kontexts</li>
<li>Beispiel 4: Die Notwendigkeit von Weltwissen</li>
</ul>
<p>Diese Beispiele werden uns helfen, die Möglichkeiten und Grenzen der aktuellen AI-Modelle besser zu verstehen und zu illustrieren, wo die Reise in Zukunft hingehen muss.## Die Macht des Kontexts in der Interaktion mit KI-Modellen</p>
<p>Stellen Sie sich vor, Sie fragen jemanden: “Wer war Goethe?” Die Antwort darauf werden Sie höchstwahrscheinlich erhalten. Doch was passiert, wenn Sie als nächstes fragen: “Wo lebte er die meiste Zeit?” Diese Information werden Sie in der Regel nicht auf Wikipedia finden. Auch eine Google-Suche wird Ihnen vermutlich keine zufriedenstellende Antwort liefern. Warum? Weil sich bisher niemand für diese spezifische Frage interessiert hat.</p>
<p>KI-Modelle sind jedoch in der Lage, solche Fragen zu beantworten, indem sie den Kontext berücksichtigen. Sie reformulieren die Frage präziser, um die dahinterstehende Absicht zu erfassen. In diesem Fall würde das Modell den Wissensbestand zu Goethes Lebensorten durchsuchen und den Ort identifizieren, an dem er die längste Zeit verbracht hat.</p>
<p>Doch was passiert, wenn man dem Modell eine Frage stellt, die ohne Kontext keinen Sinn ergibt? Nehmen wir an, ich tippe ein: “Wo lebte er die meiste Zeit?” Isoliert betrachtet ist dieser Satz unverständlich. Weder eine Suchmaschine noch ein Mensch könnte ihn beantworten. Doch KI-Modelle sind in der Lage, die Frage zu kontextualisieren. Sie reichern die Instruktion mit zusätzlichen Informationen an, um Unklarheiten und Unvollständigkeiten zu beseitigen.</p>
<section id="die-macht-des-chats" class="level3" data-number="3.7.1">
<h3 data-number="3.7.1" class="anchored" data-anchor-id="die-macht-des-chats"><span class="header-section-number">3.7.1</span> Die Macht des Chats</h3>
<p>Das Geniale an der Chat-Konstruktion ist, dass der Kontext durch die vorherigen Fragen und Antworten gebildet wird. Ihre Nachfragen und Korrekturen werden Teil des kollektiv intelligenten Kontextkonstrukts. Dadurch wird eine spätere Frage plötzlich extrem informativ, spezifisch und genau beantwortet. Der Dialog wirkt überzeugend und natürlich.</p>
<p>Nehmen wir an, ich schreibe nicht “er”, sondern “sie”. Wie würden Sie reagieren, wenn Sie am anderen Ende des Bildschirms wären und diese Frage gestellt bekämen? Die meisten von Ihnen würden wahrscheinlich davon ausgehen, dass es sich um einen Fehler handelt und die Frage trotzdem so beantworten, als ob “er” gemeint wäre.</p>
<p>Doch was passiert, wenn ich darauf bestehe, dass ich von einer weiblichen Person sprach? Das Modell entschuldigt sich höflich und passt seine Antwort entsprechend an. Es bezieht die Korrekturen mit ein und präzisiert seine Ausführungen. Im Kontext einer Diskussion über Goethe könnte es sogar die Figur der Iphigenie ins Spiel bringen.</p>
</section>
<section id="kollaborative-intelligenz" class="level3" data-number="3.7.2">
<h3 data-number="3.7.2" class="anchored" data-anchor-id="kollaborative-intelligenz"><span class="header-section-number">3.7.2</span> Kollaborative Intelligenz</h3>
<p>In Zukunft werden wir nicht mehr von einer strikten Trennung zwischen künstlicher und natürlicher Intelligenz sprechen. Stattdessen werden wir es mit hybriden Modellen zu tun haben, in denen Interaktionen zwischen Menschen und Maschinen stattfinden. Die KI wird Teil einer Wissenscommunity sein, sowohl in der Wissenschaft als auch im Alltag.</p>
<p>Problemlösungsstrategien werden auf der Zusammenarbeit von menschlicher und künstlicher Intelligenz basieren. Die Leistungsfähigkeit des Gesamtsystems wird im Vordergrund stehen, nicht die Einzelleistungen der Beteiligten.</p>
</section>
</section>
<section id="herausforderungen-und-grenzen-aktueller-ki-modelle" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="herausforderungen-und-grenzen-aktueller-ki-modelle"><span class="header-section-number">3.8</span> Herausforderungen und Grenzen aktueller KI-Modelle</h2>
<section id="einstellbare-konversationsstile" class="level3" data-number="3.8.1">
<h3 data-number="3.8.1" class="anchored" data-anchor-id="einstellbare-konversationsstile"><span class="header-section-number">3.8.1</span> Einstellbare Konversationsstile</h3>
<p>KI-Modelle verfügen über einstellbare Konversationsstile. Je nachdem, wie man sie definiert, kann man die Art und Weise der Antworten beeinflussen. Möchte man beispielsweise nur knappe, präzise Antworten ohne zusätzliche Ausführungen, lässt sich das entsprechend konfigurieren.</p>
</section>
<section id="fragen-jenseits-von-wikipedia" class="level3" data-number="3.8.2">
<h3 data-number="3.8.2" class="anchored" data-anchor-id="fragen-jenseits-von-wikipedia"><span class="header-section-number">3.8.2</span> Fragen jenseits von Wikipedia</h3>
<p>Es gibt Fragen, die selbst Wikipedia nicht beantworten kann. Nehmen wir folgendes Beispiel: “Wie viele Briefe schrieb Goethe an König Friedrich II.?” Da sich die Lebenszeiträume der beiden überschnitten und Friedrich II. großes Interesse an Aufklärungsthemen hatte, wäre ein brieflicher Austausch zwischen ihnen durchaus plausibel.</p>
<p>Doch die Antwort der KI offenbart eine Schwäche aktueller Modelle: die fehlende epistemische Prüfung der Korrektheit von Angaben. Das Modell gibt zwar eine Antwort, die plausibel klingt, aber nicht wirklich überprüft ist. Es behauptet, dass es keine Aufzeichnungen über eine direkte Kommunikation zwischen Goethe und Friedrich II. gebe. Doch wie lässt sich ein solcher Negativbefund belegen?</p>
<p>Ein trainierter Philologe würde die Gesamtkorrespondenz von Goethe konsultieren, um eine fundierte Aussage treffen zu können. Doch das Modell hat diese Prüfung nicht vorgenommen. Seine Antwort ist letztlich aus der Luft gegriffen.</p>
</section>
<section id="zukünftige-herausforderungen" class="level3" data-number="3.8.3">
<h3 data-number="3.8.3" class="anchored" data-anchor-id="zukünftige-herausforderungen"><span class="header-section-number">3.8.3</span> Zukünftige Herausforderungen</h3>
<p>Die KI-Modelle der Zukunft müssen in der Lage sein, semantische Suchen durchzuführen, inhaltliche Relevanz herzustellen und schlüssig zu argumentieren. Sie müssen historische Kontexte korrekt erfassen und historische Hypothesen anhand von Referenzen und Evidenzen beurteilen können.</p>
<p>Die größte philosophische Herausforderung besteht darin, die epistemische Qualifikation zu gewährleisten. Zu jeder Aussage und Behauptung sollte das Modell auf Nachfrage begründen können, warum es sich um die am besten gerechtfertigte Antwort handelt. Dieses Ziel zu erreichen, ist noch ein weiter Weg, aber unabdingbar für die Weiterentwicklung der KI.</p>
</section>
</section>
<section id="aktuelle-grenzen-und-zukünftige-möglichkeiten" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="aktuelle-grenzen-und-zukünftige-möglichkeiten"><span class="header-section-number">3.9</span> Aktuelle Grenzen und zukünftige Möglichkeiten</h2>
<p>Zum Abschluss möchte ich Ihnen noch zwei Beispiele präsentieren, die die aktuellen Grenzen der KI verdeutlichen. Stellen Sie sich folgendes Rätsel vor:</p>
<ul>
<li>Es gibt einen Schläger und einen Ball. Beide zusammen kosten 1,20 Euro. Der Schläger kostet einen Euro mehr als der Ball. Wie viel kostet der Ball?</li>
</ul>
<p>Diese einfache Aufgabe bringt bereits viele der derzeit existierenden KI-Modelle an ihre Grenzen. Sie sind nicht in der Lage, die korrekten logischen Schlüsse zu ziehen.</p>
<p>Noch anspruchsvoller ist folgendes Szenario:</p>
<ul>
<li>In einem Raum befinden sich drei Personen. Die erste Person liest ein Buch, die zweite Person spielt Schach. Welche Tätigkeit führt die dritte Person wahrscheinlich aus?</li>
</ul>
<p>Die meisten von Ihnen werden sofort erkennen, dass die dritte Person höchstwahrscheinlich ebenfalls Schach spielt. Doch warum ist das so? Welche Informationen benötigt die KI, um zu diesem Schluss zu kommen?</p>
<p>Genau diese Fragen stehen im Zentrum der aktuellen Forschung. Es geht darum, den Modellen beizubringen, wie sie allgemeine Regeln erkennen und anwenden können. Nur so werden sie in Zukunft in der Lage sein, auch komplexere Probleme eigenständig zu lösen.</p>
<p>Die Reise der künstlichen Intelligenz ist noch lange nicht zu Ende. Wir stehen erst am Anfang einer faszinierenden Entwicklung, die unser aller Leben nachhaltig verändern wird. Lassen Sie uns gemeinsam daran arbeiten, diese Technologie zum Wohle der Menschheit einzusetzen und ihre Grenzen immer weiter auszudehnen.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ai_Vorl2.html" class="pagination-link" aria-label="Die Revolution der AI">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Die Revolution der AI</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ai_Vorl4.html" class="pagination-link" aria-label="LLM für Sprache">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">LLM für Sprache</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© CC-By OpenScienceTechnology GmbH</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>